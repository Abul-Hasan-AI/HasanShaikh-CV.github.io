<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Hasan Shaikh</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<style>
			.posts p {
				font-size: 0.8em;
			}
			.posts ol {
				font-size: 0.8em;
				text-align: left;
			}
		</style>
		
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>Hasan Shaikh</h1>
						<!-- <img src="images\WhatsApp Image 2024-02-08 at 11.31.36 AM.jpeg" alt=" "style="border-radius: 50%; width: 500px; height: auto;"> -->
						<img src="images\headshot.jpeg" alt=" "style="border-radius: 50%; width: 500px; height: auto;">
						<p> I am a passionate Machine Learning Engineer and Data Scientist with over 6 years of experience in the industry.
							I have MSc in Artificial Intelligence with Distinction and currently specialize in Computer Vision, Object Detection, Instance segmentation, Generative AI, Computer vision on edge devices, Machine Learning, and Deep Learning. 
							I am accustomed to working in a fast-paced and diverse environment, and I thrive in it. My commitment to excellence is demonstrated by 5+ professional awards for Best Performance in the Team and Six Sigma Green Belt. 
							My mission is to leverage AI to drive innovation and solve complex problems.
						</p>
							<a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a>
						</ul>
					</div>

				<!-- Header -->
					<!-- <header id="header">
						<a href="index.html" class="logo">Massively</a>
					</header> -->

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Computer Vision projects</a></li>
							<!-- <li><a href="generic.html">Computer Vision projects</a></li>
							<li><a href="elements.html">Elements Reference</a></li> -->
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/shaikhabulhasan/" class="icon brands fa-linkedin"><span class="label">LinkedIN</span></a></li>
							<li><a href="mailto:hasanabul60@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
    						<li><a href="tel:+447564566959" class="icon solid fa-phone"><span class="label">Phone</span></a></li>
							<!-- <li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li> -->
							<!-- <li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li> -->
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Featured Post -->
							<!-- <article class="post featured">
								<header class="major">
									<span class="date">April 25, 2017</span>
									<h2><a href="#">And this is a<br />
									massive headline</a></h2>
									<p>Aenean ornare velit lacus varius enim ullamcorper proin aliquam<br />
									facilisis ante sed etiam magna interdum congue. Lorem ipsum dolor<br />
									amet nullam sed etiam veroeros.</p>
								</header>
								<a href="#" class="image main"><img src="images/pic01.jpg" alt="" /></a>
								<a href="#" class="image main" style="width: 100%; height: auto; overflow: hidden;">
									<video style="width: 100%; height: auto;" src="images/2022-11-28 13-15-04.mp4" alt="" controls></video>
								</a>
								<ul class="actions special">
									<li><a href="#" class="button large">Read More</a></li>
								</ul>
							</article> -->

						<!-- Posts -->
							<section class="posts">
								<article id="myArticle1">
									<header>
										
										<h2><a>Hot Pepper Harvester <br />
											using YOLOv8
										</a></h2>
									</header>
									<a href="javascript:void(0)" class="image fit" style="width: 100%; height: auto; overflow: hidden;">
										<video style="width: 100%; height: 100%; border: 2px solid #e3e3e3;" src="videos/Hot_pepper_harvester.mp4"  alt="" controls></video>
									</a>
									<!-- <p>Donec eget ex magna. Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis magna etiam.</p> -->
									<div id="extraContent1" style="display: none;">
										<p>
											<strong>Project Overview: Hot Pepper Harvestor Bot using YOLOv8</strong>
										</p>
										
										<p>
											Harvesting various varieties of hot peppers is challenging due to their intense heat, which makes manual handling difficult and potentially hazardous. Workers in these environments are required to wear gloves and masks to avoid irritation and burns. To address this issue, I worked with a company to build an autonomous Harvester for these peppers.
										</p>  
										
										<p>
											The video above provides a demonstration of our instance segmentation model working live. As it can be seen from the video, the model is capable of detecting the peppers as well as determining whether they are ready for harvesting or not. 
										</p>

										<p>
											The implementation involves a YOLOv8 based model that is trained to detect the pepper plants, it can identify the type of pepper and predict if the pepper are ready for harvesting. I also trained it to segment the pepper accurately to allow precise movements for their picking.   
										</p>

									</div>
									<ul class="actions special">
										<li><button class="myButton" data-target="extraContent1">Read More</a></li>
									</ul>
								</article>
								<article id="myArticle2">
									<header>
										<h2><a>Fruits Harvester assistant using Detectron2
										</a></h2>
									</header>
									<a href="javascript:void(0)" class="image fit" style="width: 100%; height: auto; overflow: hidden; ">
										<video style="width: 100%; height: auto; border: 2px solid #f0f0f0;" src="videos/client_straw_data.mp4" alt="" controls></video> 
									</a>
									
									<div id="extraContent2" style="display: none;">
										
										<p>
											<strong>Project Overview: Fruits Harvester assistant using Detectron2</strong>
										</p>
										
										<p>
											The summer fruit fields are huge in the UK, Europe and surrounding areas. So carrying picked fruits (Mostly in basket) to the storage is a very tedious and time consuming task. To solve this a startup is building robots that carry the picked fruits from to the field to the storage and other places autonomously and I helped tehm with their AI, mostly object detection side of tech. 
										</p>
										
										<p>
											To able to manoeuvre autonomously, I created a detectron2 based models that can detect drivable road, field/plant type, various static and moving obstacles, human(workers), etc. The video shows my model prediction in an actual field and how it can efficiently detect all these objects in real time.
										</p>
										
										
									</div>
									<ul class="actions special">
										<li><button class="myButton" data-target="extraContent2">Read More</button></li>
									</ul>
									</article>

								<article id="myArticle3">
									<header>
										<h2><a>Stem Cell detection in live imaging</a></h2>
									</header>
									<a href="javascript:void(0)" class="image fit" style="width: 100%; height: auto; overflow: hidden; ">
										<video style="width: 100%; height: auto; border: 2px solid #f0f0f0;" src="videos/cell_detector.mp4" alt="" controls></video> 
									</a>
									
								
									<div id="extraContent3" style="display: none;">
										
										<p>
											<strong>
												Project Overview: Detection and classification of stem cell in live imaging using Detectron2 and Transformer vision models
											</strong>
										</p>

										<p> In my previous company we were working to optimise stem cell differentiation(changing of cell from one type to another). To do this it was required to detect and track various cell nuclies and predict the type of cell they are in live imaging. Now as stem cells are live things static images and standard object detection pipelines such as Detectron Yolo don't give ideal results for identification of their type. </p>

										<p>To solve this problem, I realized that it would require additional dimensional features such as temporal and spacial features of the cell and its neigbours. So i used a combination of detectron2 architecture with variouis transformer vision architectures such as detr, vit, etc. to incorporate these feature and improve the prediction. The resulting model outperformed all our existing models by a good margin and served the pupose. The above video shows the model performance on various types of stem cell clips</p>
										<!-- <h4>Approach and Methodology</h4> -->

										<!-- <p> The project was executed in several stages, each contributing to the development and refinement of the text summarization tool. </p>

										<ol>
											<li> <strong>Selection of an Open-Source LLM:</strong> The first step involved selecting a suitable open-source LLM. The chosen model needed to have a proven track record in understanding and generating human-like text.</li>
											<li> <strong>Collection: </strong> A diverse range of research papers from the specified domains were collected. These papers served as the raw material for training and fine-tuning the LLM.</li>
											<li> <strong>Model Fine-Tuning:</strong> The LLM was then fine-tuned on the collected research papers. This step was crucial in ensuring that the model could understand and generate summaries in the context of the specific domains.</li>
											<li> <strong>Summary Generation:</strong> Once fine-tuned, the LLM was used to generate summaries of the research papers. The quality of these summaries was then evaluated based on their accuracy, coherence, and conciseness.</li>
											<li> <strong>Tool Development:</strong> The final stage involved integrating the fine-tuned LLM into a user-friendly tool. This tool allows users to input a research paper and receive a concise, coherent summary in return.</li>
										</ol>

										<h4>Results and Impact</h4>

										<p> The resulting text summarization tool demonstrated a strong ability to generate high-quality summaries of complex research papers. By condensing lengthy and intricate papers into concise summaries, the tool provides users with a quick and efficient way to understand the key points of a paper without needing to read it in full. This has the potential to save researchers significant amounts of time and make scientific knowledge more accessible to non-experts. </p>

										<p> The project serves as a testament to the power of Large Language Models in transforming the way we process and consume information. It highlights the potential of these models in making complex domains more accessible and understandable, thereby driving further innovation and discovery. </p> -->
									</div>
									<ul class="actions special">
										<li><button  class="myButton" data-target="extraContent3">Read More</button></li>
									</ul>
								</article>
								
								<article id="myArticle4">
									<header>
										<h2><a >Twitter Content Moderation</a></h2>
									</header>
									<a  class="image fit"><img src="images/twitter-2_0.png" alt="" /></a>
									
									<div id="extraContent4" style="display: none;">
										<p>
											<strong>Project Overview: ParaPhrase Detection (SemEval 2015) in Twitter Using Modern NLP Techniques</strong>
										</p>
										<p>
											This project represents my endeavor to tackle the SemEval-2015 Task 1, titled "Paraphrase Detection in Twitter". This task posed a significant challenge to computational linguistics researchers, requiring them to identify paraphrases within Twitter data. Participants were presented with pairs of sentences extracted from Twitter trends and tasked with determining whether they conveyed the same or very similar meanings.
										</p>
										
										<p>
											The performance of the systems was evaluated using several metrics, including the F-1 score and Accuracy against human judgments. Additional evaluations were provided by Pearson correlation and PINC, a measure of lexical dissimilarity. The Twitter Paraphrase Corpus, developed via crowdsourcing and containing approximately 17,790 annotated sentence pairs, was used for this task. Baseline systems, including a logistic regression model using simple lexical features and the Weighted Matrix Factorization model, were provided for comparison. This task holds significance for various NLP applications, such as summarization, sentiment analysis, textual entailment, and information extraction.
										</p>
										<!-- <p>
											For this task I used DistilBERT which is is a smaller, faster, cheaper transformer model trained by distillation of Bert base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.
											I fine uned this model to act as a binary classifier to classify whether the two sentence are paraphrases of each other. With just a little training, finetuning and hyperparameters optimisation, the model worked exceptionally well and matched the performance oif the top performing model from the original paper.
										</p> -->
										
										
										<h4>Approach and Results</h4>
										
										<p>
											For this task, I utilized DistilBERT, a smaller, faster, and more cost-effective transformer model trained by distilling BERT base. Despite having 40% fewer parameters than bert-base-uncased, DistilBERT runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark.
										</p>
										
										<p>
											I fine-tuned this model to act as a binary classifier, determining whether two sentences are paraphrases of each other. With just a bit of training, fine-tuning, and hyperparameter optimization, the model performed exceptionally well, matching the performance of the top-performing model from the original paper.
										</p>
										
									</div>
									
									<ul class="actions special">
										<li><button class="myButton" data-target="extraContent4">Read More</button></li>
									</ul>
								</article>

								<!-- <article id="myArticle5">
									<header>
										<h2><a >Semantic Similarity<br />
										detection</a></h2>
									</header>
									<a  class="image fit"><img src="images/Semantic_similarity.png" alt="" /></a>
									
									<div id="extraContent5" style="display: none;">

										<p>
											<strong>
												Project Overview: Enhancing Semantic Similarity Detection in Twitter Using Modern NLP Techniques
											</strong>
										</p>
										<p>
											This project was an exploration into the realm of semantic similarity detection within the context of Twitter data, as part of the SemEval-2015 Task 1. The task presented a unique challenge to computational linguistics researchers - to discern whether pairs of sentences, extracted from Twitter trends, conveyed the same or very similar meanings.
											This task holds enormous potential to be used in various NLP applications, such as summarization, sentiment analysis and Semantic search.
										</p>
										
										<p>
											Evaluations of system performance were based on several metrics, including F-1 score, Accuracy against human judgments, Pearson correlation, and PINC (a measure of lexical dissimilarity). The task utilized the Twitter Paraphrase Corpus, a crowdsourced collection of approximately 17,790 annotated sentence pair which were annotated by multiple human moderators in between 0 to 1 according to their Semantic similarity. 
										</p>
										
										
										<h4>Approach and Results</h4>
										
										
										<p>
											To tackle this task, I employed DistilRoberta, a compact, efficient transformer model derived from RoBERTa base. Despite its smaller size, DistilRoberta maintains over 95% of RoBERTa’s performance on the GLUE language understanding benchmark, while offering a 60% speed advantage. Compared to BERT, DistilRoberta is trained with dynamic masking rather than static masking, which makes it more efficient at understanding the context of a sentence. 
											Additionally, DistilRoberta removes the next sentence prediction objective used in BERT, which simplifies the training process without significant performance loss.
										</p>
										
										<p>
											I fine-tuned DistilRoberta to work as semantic similarity analyser and give output in an continous scale between 0 and 1 with 0 as dissimilar and 1 meaning the sentences are 100% similar to each other. 
											After a series of training iterations, fine-tuning, and hyperparameter optimization, the model demonstrated exceptional performance and was able to beat the second best performing model from original paper by a good margin.
										</p>
										

									</div>
									
									<ul class="actions special">
										<li><button class="myButton" data-target="extraContent5">Read More</button></li>
									</ul>
								</article>

								<article id="myArticle6">
									<header>
										<h2><a >Twitter offensive content<br />
										Detection</a></h2>
									</header>
									<a href="javascript:void(0)" class="image fit" style="width: 100%; height: auto; overflow: hidden;">
										<video style="width: 100%; height: 100%; border: 2px solid #e3e3e3;" src="videos/Twitter Moderator.mp4"  alt="" controls></video>
									</a>
									<div id="extraContent6" style="display: none;">

										<p>
											<strong>
												Project Overview: Offensive Content Detection and Filtering on Twitter
											</strong>
										</p>
										
										<p> This project was aimed at developing sophisticated and reliable machine learning models capable of detecting and filtering various types of offensive content, including toxicity, hate speech, attacks, racism, misogyny, white supremacy, Islamophobia, misinformation, conspiracy theories, Antivax, and vaccine hesitancy. The requirements for reliability were high accuracy reaching human levels and high speed for some of the real time filtrations.</p>
										
										<h4>Approach and Methodology</h4>
										
										<p> The project was executed in several stages, each contributing to the development and refinement of the offensive content detection and filtering models. </p>
										
										<ol>
											<li> <strong>Selection of Transformer Models:</strong> The transformer models like BERT and Roberta had state-of-the-art understanding of language hence they became the primary baseline. For requirements where filtration speed was a priority, extremely fast and lightweight versions such as DistilBERT and DistilRoberta were employed. </li>
											<li> <strong>Data Collection: </strong> Hundreds of 1000s Twitter posts were collected with tweeterAPI served as the raw material for training and fine-tuning the models. These posts were initially labelled by human annotators and the process was speed using various automated techniques, such as bootstrapping.</li>
											<li> <strong>Model Training and Fine-Tuning:</strong> The transformer models were then trained and fine-tuned using this data to act as the offensive content detectors for each of the classes as well as to understand the semantic context of the tweets. The quality of this filtering was regularly monitored and evaluated based on its accuracy and effectiveness.</li>
										   <li> <strong>Unique Approaches:</strong> These models were trained to have a unique understanding of emojis used in twitter, which is essential for understanding the semantic meaning of the tweets.  The model also became capable of understanding casual swear and other harmless content which looks offensive</li>
											<li> <strong>Model Deployment:</strong> The final stage involved deploying the fine-tuned models to AWS cloud, where they are currently being used to filter offensive content on Twitter using third party apps and APIs.</li>
										</ol>
										
										<h4>Results and Impact</h4>
										
										<p> The resulting offensive content detection and filtering models demonstrated a strong ability to detect and filter various types of offensive content on Twitter reaching almost 98% of accuracy for most types of content. By filtering out offensive content, the models provide users with a safer and more pleasant Twitter experience. This has the potential to improve the overall quality of content on Twitter and make our platform more welcoming for all users. </p>
										
										
																			
											
									</div>
									

									
									<ul class="actions special">
										<li><button class="myButton" data-target="extraContent6">Read More</button></li>
									</ul>
								</article> -->
								
							</section>
							<script>
								var buttons = document.getElementsByClassName("myButton");
								console.log("buttons:", buttons.length, buttons)
								for (var i = 0; i < buttons.length; i++) {
									buttons[i].addEventListener("click", function() {
										var targetId = this.getAttribute("data-target");
										var x = document.getElementById(targetId);
										console.log("targetId:", targetId);  // Add this line
										console.log("target element:", x);  // Add this line
										if (x.style.display === "none") {
											x.style.display = "block";
											this.textContent = "Read Less";
										} else {
											x.style.display = "none";
											this.textContent = "Read More";
										}
									});
								}
								
							</script>

						<!-- Footer -->
							<!-- <footer>
								<div class="pagination">
									<a href="#" class="previous">Prev</a>
									<a href="#" class="page active">1</a>
									<a href="#" class="page">2</a>
									<a href="#" class="page">3</a>
									<span class="extra">&hellip;</span>
									<a href="#" class="page">8</a>
									<a href="#" class="page">9</a>
									<a href="#" class="page">10</a>
									<a href="#" class="next">Next</a>
								</div>
							 </footer> --> 

					</div>

				<!-- Footer -->
					<footer id="footer">
						<!-- <section>
							<form method="post" action="#">
								<div class="fields">
									<div class="field">
										<label for="name">Name</label>
										<input type="text" name="name" id="name" />
									</div>
									<div class="field">
										<label for="email">Email</label>
										<input type="text" name="email" id="hasanabul60@gmail.com" />
									</div>
									<div class="field">
										<label for="message">Message</label>
										<textarea name="message" id="message" rows="3"></textarea>
									</div>
								</div>
								<ul class="actions">
									<li><input type="submit" value="Send Message" /></li>
								</ul>
							</form>
						</section> -->
						<!-- <section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>1234 Somewhere Road #87257<br />
								Nashville, TN 00000-0000</p>
							</section>
							<section>
								<h3>Phone</h3>
								<p><a href="#">(000) 000-0000</a></p>
							</section>
							<section>
								<h3>Email</h3>
								<p><a href="#">info@untitled.tld</a></p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section> -->
						
							<section class="contact">
								<div style="display: flex; flex-wrap: wrap; justify-content: space-between;">
									<div>
										<h3>Location</h3>
										<p>
										London, UK</p>
									</div>
									<div>
										<h3>Phone</h3>
										<p><a href="#">(+44) 7564566959</a></p>
									</div>
									<div>
										<h3>Email</h3>
										<p><a href="#">hasanabul60@gmail.com</a></p>
									</div>
									<div>
										<h3>Social</h3>
										<ul class="icons alt">
											<li><a href="https://www.linkedin.com/in/shaikhabulhasan/" class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
											<!-- <li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li> -->
											<!-- <li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li> -->
										</ul>
									</div>
								</div>
							</section>
						
						
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Abul Hasan Shaikh</li><li>Design: <a >HTML5</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>